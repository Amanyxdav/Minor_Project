{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow : TensorFlow is an end-to-end open source platform for machine learning. It has a particular focus on training and inference of deep neural networks.\n",
    "\n",
    "TensorFlow vs Keras : TensorFlow is an open-sourced end-to-end platform, a library for multiple machine learning tasks, while Keras is a high-level neural network library that runs on top of TensorFlow. \n",
    "\n",
    "Keras : Keras is an open-source software library that provides a Python interface for artificial neural networks. \n",
    "\n",
    "Keras : Keras acts as an interface for the TensorFlow library.\n",
    "\n",
    "Keras : Keras is used for implementing neural networks. \n",
    "\n",
    "Sequential : A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "Conv2D : 2D convolution layer (e.g. spatial convolution over images). \n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. \n",
    "If use_bias is True, a bias vector is created and added to the outputs. \n",
    "\n",
    " - kernel_size : An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "\n",
    " - activation : If activation is not None, it is applied to the outputs as well. If you don't specify anything, no activation is applied.\n",
    " - activation='relu' : Applies the rectified linear unit activation function.\n",
    "\n",
    " - input_shape : When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\". You can use None when a dimension has variable size.\n",
    "\n",
    "\n",
    "Max pooling : Max pooling operation for 2D spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size ) for each channel of the input. The window is shifted by strides along each dimension.\n",
    " - pool_size : integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "\n",
    "Dense : The dense layer in neural networks is the one that executes matrix-vector multiplication. The matrix parameters are retrieved by updating and training using the backpropagation methodology. The final result of the dense layer is the vector of n dimensions.\n",
    " - units : Positive integer, dimensionality of the output space.\n",
    " - activation : If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "Dropout : Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "\n",
    "Flatten : Tensorflow flatten is the function available in the tensorflow library and reduces the input data into a single dimension instead of 2 dimensions. While doing so, it does not affect the batch size. (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "# OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.\n",
    "import cv2\n",
    "\n",
    "# Keras is used for implementing neural networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import Adam\n",
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "# ImageDataGenerator are used for preprocessing of all the images\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)  # For training purpose \n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)  # For testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all train images\n",
    "\n",
    "# flow_from_directory is a very good tool in the keras where you can make use of it to just flow through the directories and collect all the data and pre-process it\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        'D:\\Project\\HED\\Emotion_detection_with_CNN-main/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "# the class_mode will be the categoricals itmeans that whatever the folder structurewe have provided according to thatit will create a categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all test images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        'D:\\Project\\HED\\Emotion_detection_with_CNN-main/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our both generators are ready train generator and well data generators it means that our all the training and validation/testing data is now pre-processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1))) # input shape 1 means only 1 colur channel that is grayscale, THIS IS CONVOLUTION LAYER 1\n",
    "# all the images pre-processed with the 48 by 48 size and color code is a grayscale it means it is having the only one color channel so here i am passing the input shape as a 48 by 48 pixel and color is only one gray scale so i am passing the color channel as a one if it is a rgb image then we have to pass it like a three \n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) #THIS IS CONVOLUTION LAYER 2\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25)) #to avoid the overfitting we are just going to do the drop out with 0.25 \n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax')) # Here 7 means 7 reactions/emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential : A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "Conv2D : 2D convolution layer (e.g. spatial convolution over images). \n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. \n",
    "If use_bias is True, a bias vector is created and added to the outputs. \n",
    "\n",
    " - kernel_size : An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "\n",
    " - activation : If activation is not None, it is applied to the outputs as well. If you don't specify anything, no activation is applied.\n",
    " - activation='relu' : Applies the rectified linear unit activation function.\n",
    "\n",
    " - input_shape : When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\". You can use None when a dimension has variable size.\n",
    "\n",
    "Max pooling : Max pooling operation for 2D spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size ) for each channel of the input. The window is shifted by strides along each dimension.\n",
    " - pool_size : integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "\n",
    "Dense : The dense layer in neural networks is the one that executes matrix-vector multiplication. The matrix parameters are retrieved by updating and training using the backpropagation methodology. The final result of the dense layer is the vector of n dimensions.\n",
    " - units : Positive integer, dimensionality of the output space.\n",
    " - activation : If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "Dropout : Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "\n",
    "Flatten : Tensorflow flatten is the function available in the tensorflow library and reduces the input data into a single dimension instead of 2 dimensions. While doing so, it does not affect the batch size. (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    " \n",
    "Weight_decay: Float, defaults to None. If set, weight decay  is applied.\n",
    "\n",
    "Adam is an alternative optimization algorithm that provides more efficient neural network weights by running repeated cycles of “adaptive moment estimation.” \n",
    "\n",
    "The optimizer Adam works well and is the most popular optimizer nowadays. Adam typically requires a smaller learning rate: start at 0.001, then increase/decrease as you see fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Softwares\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the neural network/model\n",
    "# emotion_model_info = emotion_model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=28709 // 64,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=7178 // 64)\n",
    "\n",
    "\n",
    "# # epoch is a total number of images divided by 64 and this training will happen for the 50 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model structure in json file\n",
    "# model_json = emotion_model.to_json()\n",
    "# with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save trained model weight in .h5 file\n",
    "# emotion_model.save_weights('emotion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation_generator[0])\n",
    "print(len(validation_generator[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "emotion_model=load_model('emotion_model.h5')\n",
    "emotion_model.evaluate(validation_generator[0],validation_generator[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_model_history(model_history):\n",
    "#     \"\"\"\n",
    "#     Plot Accuracy and Loss curves given the model_history\n",
    "#     \"\"\"\n",
    "#     fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "#     # summarize history for accuracy\n",
    "#     axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "#     axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "#     axs[0].set_title('Model Accuracy')\n",
    "#     axs[0].set_ylabel('Accuracy')\n",
    "#     axs[0].set_xlabel('Epoch')\n",
    "#     axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "#     axs[0].legend(['train', 'val'], loc='best')\n",
    "#     # summarize history for loss\n",
    "#     axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "#     axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "#     axs[1].set_title('Model Loss')\n",
    "#     axs[1].set_ylabel('Loss')\n",
    "#     axs[1].set_xlabel('Epoch')\n",
    "#     axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "#     axs[1].legend(['train', 'val'], loc='best')\n",
    "#     fig.savefig('plot.png')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot_model_history(emotion_model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b9421b5222da2867aabbb111c01a47ecd976a453d0e487de23fa3aaa8e98ee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
